import os
import pandas as pd
import numpy as np
import torch
import joblib
import requests
import json
from sqlalchemy import create_engine, text
from dotenv import load_dotenv
from datetime import datetime, timedelta
from gnn_model import ST_GNN # Import class m√¥ h√¨nh

# C·∫•u h√¨nh
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
HCMC_GRID = [
  { 'id': 'ThuDuc', 'lat': 10.8231, 'lon': 106.7711 },
  { 'id': 'District12', 'lat': 10.8672, 'lon': 106.6415 },
  { 'id': 'HocMon', 'lat': 10.8763, 'lon': 106.5941 },
  { 'id': 'District1', 'lat': 10.7769, 'lon': 106.7009 },
  { 'id': 'BinhTan', 'lat': 10.7656, 'lon': 106.6031 },
  { 'id': 'District2', 'lat': 10.7877, 'lon': 106.7407 },
  { 'id': 'District7', 'lat': 10.734, 'lon': 106.7206 },
  { 'id': 'BinhChanh', 'lat': 10.718, 'lon': 106.6067 },
  { 'id': 'CanGio', 'lat': 10.518, 'lon': 106.8776 },
]
NUM_NODES = len(HCMC_GRID)
SEQ_LENGTH = 4

def get_db_engine():
    env_path = os.path.join(BASE_DIR, '..', '..', '.env')
    load_dotenv(env_path)
    db_url = f"postgresql://{os.getenv('DB_USER')}:{os.getenv('DB_PASS')}@" \
             f"{os.getenv('DB_HOST')}:{os.getenv('DB_PORT')}/{os.getenv('DB_NAME')}"
    return create_engine(db_url), os.getenv('ORION_LD_URL')

def get_latest_network_data(engine):
    """L·∫•y d·ªØ li·ªáu m·ªõi nh·∫•t c·ªßa TO√ÄN B·ªò 9 tr·∫°m ƒë·ªÉ t·∫°o th√†nh 1 snapshot"""
    data_matrix = [] # S·∫Ω ch·ª©a [Num_Nodes, Seq_Len]
    latest_time = None

    for grid_point in HCMC_GRID:
        query = text(f"""
            SELECT time, pm2_5 
            FROM air_quality_observations 
            WHERE entity_id = 'urn:ngsi-ld:AirQualityStation:OWM-{grid_point['id']}' 
            ORDER BY time DESC 
            LIMIT {SEQ_LENGTH}
        """)
        with engine.connect() as conn:
            df = pd.read_sql(query, conn)
        
        if len(df) < SEQ_LENGTH:
            raise ValueError(f"Tr·∫°m {grid_point['id']} kh√¥ng ƒë·ªß d·ªØ li·ªáu")
        
        # ƒê·∫£o ng∆∞·ª£c ƒë·ªÉ ƒë√∫ng th·ª© t·ª± th·ªùi gian (C≈© -> M·ªõi)
        values = df['pm2_5'].values[::-1]
        data_matrix.append(values)
        
        # L·∫•y th·ªùi gian c·ªßa ƒëi·ªÉm d·ªØ li·ªáu m·ªõi nh·∫•t
        if latest_time is None:
            latest_time = df['time'].iloc[0]

    # K·∫øt qu·∫£ shape: [Num_Nodes, Seq_Len] -> Chuy·ªÉn th√†nh [Num_Nodes, Seq_Len, 1]
    return np.array(data_matrix)[..., np.newaxis], pd.to_datetime(latest_time)

def sync_to_orion(orion_url, grid_point, value, time):
    entity_id = f"urn:ngsi-ld:AirQualityForecast:OWM-{grid_point['id']}"
    forecast_time = time + timedelta(minutes=15)
    
    payload = {
        "id": entity_id,
        "type": "AirQualityForecast",
        "location": { "type": "GeoProperty", "value": { "type": "Point", "coordinates": [grid_point['lon'], grid_point['lat']] } },
        "validFrom": { "type": "Property", "value": { "@type": "DateTime", "@value": forecast_time.isoformat() } },
        "forecastedPM25": { "type": "Property", "value": round(float(value), 2), "unitCode": "¬µg/m¬≥" },
        "@context": ["https://smartdatamodels.org/context.jsonld"]
    }
    
    headers = { 'Content-Type': 'application/ld+json' }
    try:
        requests.post(orion_url, headers=headers, data=json.dumps(payload))
        print(f"‚úÖ [GNN] T·∫°o m·ªõi: {grid_point['id']} -> {payload['forecastedPM25']['value']}")
    except:
        # N·∫øu ƒë√£ t·ªìn t·∫°i th√¨ Patch
        patch_payload = { "forecastedPM25": payload["forecastedPM25"], "validFrom": payload["validFrom"] }
        requests.patch(f"{orion_url}/{entity_id}/attrs", headers={'Content-Type': 'application/json'}, data=json.dumps(patch_payload))
        print(f"üîÑ [GNN] C·∫≠p nh·∫≠t: {grid_point['id']} -> {payload['forecastedPM25']['value']}")

def main():
    engine, orion_url = get_db_engine()
    print(f"\n--- B·∫ÆT ƒê·∫¶U D·ª∞ B√ÅO GNN (M·∫°ng ƒê·ªì Th·ªã) ---")

    try:
        # 1. Load Model & Graph Structure
        model = ST_GNN(num_nodes=NUM_NODES, input_dim=1, hidden_dim=16, output_dim=1)
        model.load_state_dict(torch.load(os.path.join(BASE_DIR, 'gnn_model.pth')))
        model.eval()
        
        scaler = joblib.load(os.path.join(BASE_DIR, 'gnn_scaler.joblib'))
        edge_index, edge_weight = torch.load(os.path.join(BASE_DIR, 'graph_structure.pt'))

        # 2. L·∫•y d·ªØ li·ªáu m·∫°ng l∆∞·ªõi
        raw_data, last_time = get_latest_network_data(engine)
        
        # 3. Chu·∫©n h√≥a (C·ª±c quan tr·ªçng: Ph·∫£i reshape ƒë·ªÉ scale ƒë√∫ng c·ªôt)
        # Scaler h·ªçc tr√™n DataFrame (c·ªôt = tr·∫°m), n√™n ta ph·∫£i ƒë∆∞a v·ªÅ d·∫°ng (Time, Nodes)
        # raw_data ƒëang l√† (Nodes, Time, 1) -> (Time, Nodes)
        input_2d = raw_data.squeeze().T 
        input_scaled = scaler.transform(input_2d)
        
        # Reshape l·∫°i v·ªÅ Tensor cho GNN (Nodes, Time, Features)
        input_tensor = torch.tensor(input_scaled.T[..., np.newaxis], dtype=torch.float)

        # 4. D·ª± b√°o (Forward Pass)
        with torch.no_grad():
            out = model(input_tensor, edge_index, edge_weight) # Shape: [9, 1]
            
        # 5. Gi·∫£i m√£ (Inverse Transform)
        # Output model l√† (Nodes, 1) -> C·∫ßn ƒë∆∞a v·ªÅ (1, Nodes) ƒë·ªÉ inverse_transform
        pred_dummy = np.zeros((1, NUM_NODES)) # Dummy array kh·ªõp v·ªõi shape scaler
        pred_dummy[0] = out.squeeze().numpy()
        pred_actual = scaler.inverse_transform(pred_dummy)[0]

        # 6. ƒê·∫©y k·∫øt qu·∫£ l√™n Orion
        for i, val in enumerate(pred_actual):
            val = max(0.0, val) # K·∫πp gi√° tr·ªã d∆∞∆°ng
            sync_to_orion(orion_url, HCMC_GRID[i], val, last_time)

    except Exception as e:
        print(f"‚ùå L·ªói d·ª± b√°o GNN: {e}")

if __name__ == "__main__":
    main()